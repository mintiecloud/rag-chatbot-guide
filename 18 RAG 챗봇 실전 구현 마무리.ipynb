{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 7. RAG 챗봇 실전 구현 마무리\n",
    "\n",
    "지금까지 우리는 단순한 LLM 호출을 넘어서, 실제 서비스 수준의 **문서 기반 RAG 챗봇**을 직접 설계하고 구현해보았습니다.  \n",
    "이번 장에서는 전체 흐름을 정리하고, 실무 적용 시 고려할 최적화 포인트와 확장 전략을 소개합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 1. 우리가 만든 챗봇 구조 요약\n",
    "\n",
    "```text\n",
    "[사용자 질문] → [검색기 (Retriever)] → [문서 선택] → [LLM 응답 생성] → [최종 응답]\n",
    "````\n",
    "\n",
    "### 🔧 핵심 구성 요소\n",
    "\n",
    "| 구성 요소               | 역할                          |\n",
    "| ------------------- | --------------------------- |\n",
    "| Vector DB (FAISS)   | 내 문서를 벡터로 변환하여 저장하고 검색      |\n",
    "| Embedding 모델        | 문장 간 의미 유사도 계산을 위한 임베딩 생성   |\n",
    "| Retriever           | 사용자의 질문과 유사한 문서를 검색 (Top-K) |\n",
    "| LLM (gpt-3.5-turbo) | 검색된 문서를 바탕으로 자연스러운 답변 생성    |\n",
    "| UI (Streamlit)      | 사용자 입력/응답을 처리하는 웹 인터페이스     |\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 2. 강의별 학습 내용 요약\n",
    "\n",
    "| 주요 주제                                    |\n",
    "| ---------------------------------------- |\n",
    "| RAG의 개념, 문서 임베딩 및 벡터 검색 기본               |\n",
    "| 검색 품질 튜닝: Top-K, Score, L2 거리, 임계값 필터링   |\n",
    "| 의미 유사도 기반 응답 생성 (`RetrievalQA` 체인 구성)    |\n",
    "| 내 문서 기반 RAG 챗봇 완성 (Stuff 방식 사용)          |\n",
    "| Chunking 전략 고도화 (Overlap, Chunk Size 실험) |\n",
    "| Hybrid Search: BM25 + FAISS 결합 검색        |\n",
    "| 응답 속도 최적화 전략 (Top-K, 문서 제한, 캐싱 등)        |\n",
    "| Streamlit으로 UI 구성하여 챗봇 배포 준비 완료          |\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 3. 실무 적용 시 최적화 팁\n",
    "\n",
    "### 🔧 성능 개선을 위한 전략\n",
    "\n",
    "* **Top-K는 3\\~5 내외**로 조절: 너무 많으면 응답 품질 저하\n",
    "* **Chunking은 문서 구조별로 조정**: overlap=30\\~100 사이 추천\n",
    "* **Embedding & Index 캐싱 필수**: `.save_local()` 및 `load_local()` 활용\n",
    "* **Streamlit 앱에서는 `@st.cache_resource` 사용**으로 초기화 시간 최소화\n",
    "\n",
    "---\n",
    "\n",
    "## 🌐 4. 실전 서비스로 확장하려면?\n",
    "\n",
    "| 고려 요소     | 설명                                          |\n",
    "| --------- | ------------------------------------------- |\n",
    "| API 기반 분리 | 백엔드(검색/생성)와 프론트엔드(Streamlit, React 등) 분리 설계 |\n",
    "| 사용자 관리    | 로그인, 세션 기반 질문 이력 저장 기능                      |\n",
    "| 문서 추가     | 새로운 문서 업로드 시 자동 임베딩 & 인덱스 갱신 파이프라인 구축       |\n",
    "| 비용 절감     | OpenAI 호출 수 줄이기 위한 캐싱, 로컬 LLM 사용 고려         |\n",
    "| 멀티문서      | 고객사별 문서 구분, 필터링 기능 추가 (메타정보 기반 RAG)         |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 5. 배포 방법 안내\n",
    "\n",
    "### 💻 로컬 실행\n",
    "\n",
    "```bash\n",
    "streamlit run streamlit_app.py\n",
    "```\n",
    "\n",
    "### ☁️ 클라우드 배포\n",
    "\n",
    "* [Streamlit Cloud](https://streamlit.io/cloud) 사용 (GitHub 연동)\n",
    "* 또는 AWS, GCP, Azure, Vercel 등 일반 웹 서버로 배포\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 마무리\n",
    "\n",
    "> 이번 프로젝트를 통해 여러분은 단순한 LLM 활용을 넘어서,\n",
    "> 실제로 \\*\\*\"내 문서에 답할 수 있는 RAG 챗봇을 직접 설계하고 서비스할 수 있는 수준\"\\*\\*에 도달했습니다.\n",
    "\n",
    "이제 이 구조를 바탕으로 자신만의 문서, 자신만의 산업에 맞는 챗봇을 만들고 확장해보세요.\n",
    "\\*\\*\"내가 구축한 챗봇이 실제 고객의 질문에 답변하고 있다\"\\*\\*는 경험은 정말 특별할 거예요.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎉 고생하셨습니다! 다음 강의에서 다시 만나요 🎥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
