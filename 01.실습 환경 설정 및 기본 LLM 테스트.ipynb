{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. ì‹¤ìŠµ í™˜ê²½ ì¤€ë¹„ ë° í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- íŒŒì´ì¬ ì„¤ì¹˜ : https://www.python.org/downloads/\n",
    "- ê°€ìƒí™˜ê²½ ìƒì„± (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)\n",
    "  - python -m venv rag-env    \n",
    "- ê°€ìƒí™˜ê²½ í™œì„±í™”\n",
    "  - Mac : source rag-env/bin/activate  \n",
    "  - Window : rag-env\\Scripts\\activate\n",
    "- ì´í›„ ì•„ë˜ íŒ¨í‚¤ì§€ë¥¼ ìµœì´ˆ 1íšŒë§Œ ì„¤ì¹˜ (í„°ë¯¸ë„ or ë…¸íŠ¸ë¶íŒŒì¼ ë‚´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# pip install -U langchain-openai langchain langchain-community openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "- https://platform.openai.com/api-keys ì—ì„œ API ë°œê¸‰\n",
    "- .env íŒŒì¼ í•„ìš”\n",
    "  - .env íŒŒì¼ ë‚´ìš©: OPENAI_API_KEY=sk-..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ OpenAI API í‚¤ ë¡œë”© ì„±ê³µ!\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key:\n",
    "    print(\"ğŸ”‘ OpenAI API í‚¤ ë¡œë”© ì„±ê³µ!\")\n",
    "else:\n",
    "    print(\"âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LangChainì„ í™œìš©í•œ OpenAI ëª¨ë¸ í˜¸ì¶œ í…ŒìŠ¤íŠ¸\n",
    "- https://platform.openai.com/api-keys ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# temperature, model_name ë“± ì£¼ìš” íŒŒë¼ë¯¸í„° ì§€ì •\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.5,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LangChainì˜ ë‹¤ì–‘í•œ ì…ë ¥ ë°©ì‹ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. invoke() ì‚¬ìš© "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ ë‹µë³€ (invoke ì‚¬ìš©): RAG(Retrieval-Augmented Generation)ëŠ” ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ë¡œ, ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ ë°©ì‹ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. RAGëŠ” ë¨¼ì € ëŒ€ê·œëª¨ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•œ í›„, ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë” ì •í™•í•˜ê³  ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. RAGëŠ” ì£¼ë¡œ ëŒ€í™” ì‹œìŠ¤í…œ, ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ, ìš”ì•½ ìƒì„± ë“± ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì— í™œìš©ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response2 = llm.invoke(\"RAG(Retrieval-Augmented Generation)ê°€ ë­ì•¼?\")\n",
    "print(\"ğŸ“¨ ë‹µë³€ (invoke ì‚¬ìš©):\", response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. ë‹¤ì–‘í•œ ë©”ì‹œì§€ íƒ€ì… í…ŒìŠ¤íŠ¸ \n",
    "- SystemMessage í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ ë‹µë³€ (SystemMessage í¬í•¨): RAG(ê²€ìƒ‰ ë³´ì¡° ìƒì„±)ì€ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ ì¤‘ í•˜ë‚˜ë¡œ, ê²€ìƒ‰ ê¸°ëŠ¥ì„ í†µí•´ ìƒì„± ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ê²€ìƒ‰ ì—”ì§„ì„ í™œìš©í•´ ì…ë ¥ ë¬¸ì¥ì— ê´€ë ¨ëœ ì •ë³´ë¥¼ ê²€ìƒ‰í•œ í›„, ì´ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê°„ë‹¨íˆ ë§í•´, RAGëŠ” ìƒì„± ëª¨ë¸ê³¼ ê²€ìƒ‰ ì—”ì§„ì„ ê²°í•©í•˜ì—¬ ë”ìš± ì •í™•í•˜ê³  ì˜ë¯¸ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ê¸°ìˆ ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìì—°ì–´ ì²˜ë¦¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì— í™œìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"ë„ˆëŠ” ì¹œì ˆí•œ AIì•¼. ì´ˆë³´ì ëˆˆë†’ì´ì— ë§ì¶° ìì„¸íˆ ì„¤ëª…í•´ì¤˜.\"),\n",
    "    HumanMessage(content=\"RAG(Retrieval-Augmented Generation)ê°€ ë­ì•¼?\")\n",
    "]\n",
    "response3 = llm(messages)\n",
    "print(\"ğŸ“¨ ë‹µë³€ (SystemMessage í¬í•¨):\", response3.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
